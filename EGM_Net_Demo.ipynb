{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a590fe",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision numpy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/QuocKhanhLuong/FourierNetwork.git\n",
    "%cd FourierNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f537f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üñ•Ô∏è Using device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9567d48f",
   "metadata": {},
   "source": [
    "## 2. Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our models\n",
    "from monogenic import EnergyMap, MonogenicSignal, BoundaryDetector\n",
    "from gabor_implicit import GaborBasis, GaborNet, ImplicitSegmentationHead\n",
    "from egm_net import EGMNet, EGMNetLite\n",
    "from spectral_mamba import SpectralVMUNet\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47b55f",
   "metadata": {},
   "source": [
    "## 3. Test Monogenic Signal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test image with edges\n",
    "def create_test_image(size=256):\n",
    "    \"\"\"Create synthetic medical-like image with organs.\"\"\"\n",
    "    img = torch.zeros(1, 1, size, size)\n",
    "    \n",
    "    # Add circular \"organ\"\n",
    "    y, x = torch.meshgrid(torch.arange(size), torch.arange(size), indexing='ij')\n",
    "    center1 = (size // 2, size // 2)\n",
    "    radius1 = size // 4\n",
    "    mask1 = ((x - center1[0])**2 + (y - center1[1])**2) < radius1**2\n",
    "    img[0, 0, mask1] = 0.7\n",
    "    \n",
    "    # Add smaller \"tumor\"\n",
    "    center2 = (size // 2 + 30, size // 2 - 20)\n",
    "    radius2 = size // 10\n",
    "    mask2 = ((x - center2[0])**2 + (y - center2[1])**2) < radius2**2\n",
    "    img[0, 0, mask2] = 1.0\n",
    "    \n",
    "    # Add noise\n",
    "    img = img + 0.05 * torch.randn_like(img)\n",
    "    \n",
    "    return img, mask1.float(), mask2.float()\n",
    "\n",
    "# Create test image\n",
    "test_img, organ_mask, tumor_mask = create_test_image(256)\n",
    "print(f\"Test image shape: {test_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18065bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Monogenic Energy Extraction\n",
    "energy_extractor = EnergyMap(normalize=True, smoothing_sigma=1.0)\n",
    "energy, mono_out = energy_extractor(test_img)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(test_img[0, 0], cmap='gray')\n",
    "axes[0, 0].set_title('Input Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(energy[0, 0].detach(), cmap='hot')\n",
    "axes[0, 1].set_title('Energy Map (Edges)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(mono_out['phase'][0, 0].detach(), cmap='twilight')\n",
    "axes[0, 2].set_title('Phase')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(mono_out['orientation'][0, 0].detach(), cmap='hsv')\n",
    "axes[1, 0].set_title('Orientation')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(mono_out['riesz_x'][0, 0].detach(), cmap='RdBu')\n",
    "axes[1, 1].set_title('Riesz X Component')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(mono_out['riesz_y'][0, 0].detach(), cmap='RdBu')\n",
    "axes[1, 2].set_title('Riesz Y Component')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('Monogenic Signal Decomposition', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Monogenic processing works correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee600ecb",
   "metadata": {},
   "source": [
    "## 4. Test Gabor Basis vs Fourier Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gabor_implicit import GaborBasis, FourierFeatures\n",
    "\n",
    "# Create coordinate grid\n",
    "size = 128\n",
    "y = torch.linspace(-1, 1, size)\n",
    "x = torch.linspace(-1, 1, size)\n",
    "yy, xx = torch.meshgrid(y, x, indexing='ij')\n",
    "coords = torch.stack([xx, yy], dim=-1).view(1, -1, 2)  # (1, size*size, 2)\n",
    "\n",
    "# Compare Gabor vs Fourier\n",
    "gabor = GaborBasis(input_dim=2, num_frequencies=32)\n",
    "fourier = FourierFeatures(input_dim=2, num_frequencies=32, scale=10.0)\n",
    "\n",
    "gabor_features = gabor(coords)\n",
    "fourier_features = fourier(coords)\n",
    "\n",
    "print(f\"Gabor features shape: {gabor_features.shape}\")\n",
    "print(f\"Fourier features shape: {fourier_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first few basis functions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(4):\n",
    "    # Gabor\n",
    "    gabor_vis = gabor_features[0, :, i].view(size, size).detach().numpy()\n",
    "    axes[0, i].imshow(gabor_vis, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[0, i].set_title(f'Gabor Basis {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Fourier\n",
    "    fourier_vis = fourier_features[0, :, i].view(size, size).detach().numpy()\n",
    "    axes[1, i].imshow(fourier_vis, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[1, i].set_title(f'Fourier Basis {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('Gabor\\n(Localized)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Fourier\\n(Global)', fontsize=12)\n",
    "\n",
    "plt.suptitle('Gabor vs Fourier Basis Functions\\n(Gabor is localized ‚Üí No Gibbs ringing)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8ef9df",
   "metadata": {},
   "source": [
    "## 5. Create and Analyze Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c426ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EGM-Net models\n",
    "print(\"Creating models...\")\n",
    "\n",
    "# Full model\n",
    "egm_net = EGMNet(\n",
    "    in_channels=1,\n",
    "    num_classes=3,\n",
    "    img_size=256,\n",
    "    base_channels=64,\n",
    "    num_stages=4,\n",
    "    encoder_depth=2\n",
    ").to(device)\n",
    "\n",
    "# Lite model\n",
    "egm_lite = EGMNetLite(\n",
    "    in_channels=1,\n",
    "    num_classes=3,\n",
    "    img_size=256\n",
    ").to(device)\n",
    "\n",
    "# Spectral Mamba (comparison)\n",
    "spec_mamba = SpectralVMUNet(\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    img_size=256,\n",
    "    base_channels=64,\n",
    "    num_stages=4\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nüìä Model Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "models = {\n",
    "    'EGM-Net Full': egm_net,\n",
    "    'EGM-Net Lite': egm_lite,\n",
    "    'SpectralVMUNet': spec_mamba\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{name:20s}: {params:,} parameters ({params/1e6:.2f}M)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeffa14a",
   "metadata": {},
   "source": [
    "## 6. Test Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c023bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "test_input = torch.randn(2, 1, 256, 256).to(device)\n",
    "\n",
    "print(\"Testing forward pass...\")\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # EGM-Net\n",
    "    egm_out = egm_net(test_input)\n",
    "    print(f\"\\nüîπ EGM-Net Output:\")\n",
    "    for k, v in egm_out.items():\n",
    "        print(f\"   {k}: {v.shape}\")\n",
    "    \n",
    "    # SpectralVMUNet\n",
    "    spec_out = spec_mamba(test_input)\n",
    "    print(f\"\\nüîπ SpectralVMUNet Output: {spec_out.shape}\")\n",
    "\n",
    "print(\"\\n‚úÖ Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4b153",
   "metadata": {},
   "source": [
    "## 7. Test Resolution-Free Inference (Unique to EGM-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb14e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EGM-Net can query at arbitrary coordinates!\n",
    "print(\"Testing Resolution-Free Inference...\")\n",
    "\n",
    "# Create query points (random locations)\n",
    "num_points = 10000\n",
    "random_coords = torch.rand(1, num_points, 2).to(device) * 2 - 1  # [-1, 1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Query at random points\n",
    "    point_output = egm_net.query_points(test_input[:1], random_coords)\n",
    "    \n",
    "print(f\"Query coordinates: {random_coords.shape}\")\n",
    "print(f\"Point outputs: {point_output.shape}\")\n",
    "print(\"\\n‚úÖ Resolution-free inference works!\")\n",
    "print(\"   ‚Üí You can zoom into boundaries at ANY resolution!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate resolution-free: render at different resolutions\n",
    "resolutions = [64, 128, 256, 512]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, res in enumerate(resolutions):\n",
    "        # Render at this resolution\n",
    "        output = egm_net(test_input[:1], output_size=(res, res))\n",
    "        pred = torch.argmax(output['output'], dim=1)[0].cpu().numpy()\n",
    "        \n",
    "        axes[idx].imshow(pred, cmap='viridis')\n",
    "        axes[idx].set_title(f'{res}√ó{res}')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Resolution-Free Rendering (Same model, different output sizes)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04640dc",
   "metadata": {},
   "source": [
    "## 8. Visualize Energy-Gated Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01794b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dual-branch architecture\n",
    "with torch.no_grad():\n",
    "    outputs = egm_net(test_input[:1])\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Input\n",
    "axes[0, 0].imshow(test_input[0, 0].cpu(), cmap='gray')\n",
    "axes[0, 0].set_title('Input Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Energy Map\n",
    "axes[0, 1].imshow(outputs['energy'][0, 0].cpu(), cmap='hot')\n",
    "axes[0, 1].set_title('Energy Map (Edge Detection)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Coarse Branch\n",
    "coarse_pred = torch.argmax(outputs['coarse'], dim=1)[0].cpu()\n",
    "axes[0, 2].imshow(coarse_pred, cmap='viridis')\n",
    "axes[0, 2].set_title('Coarse Branch (Smooth)')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Fine Branch\n",
    "fine_pred = torch.argmax(outputs['fine'], dim=1)[0].cpu()\n",
    "axes[1, 0].imshow(fine_pred, cmap='viridis')\n",
    "axes[1, 0].set_title('Fine Branch (Sharp)')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Final Output\n",
    "final_pred = torch.argmax(outputs['output'], dim=1)[0].cpu()\n",
    "axes[1, 1].imshow(final_pred, cmap='viridis')\n",
    "axes[1, 1].set_title('Final Output (Fused)')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Difference\n",
    "diff = (fine_pred != coarse_pred).float()\n",
    "axes[1, 2].imshow(diff, cmap='Reds')\n",
    "axes[1, 2].set_title('Difference (Fine vs Coarse)')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('EGM-Net Dual-Branch Architecture', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c51b26",
   "metadata": {},
   "source": [
    "## 9. Quick Training Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d86f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_egm import EGMNetTrainer, create_dummy_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create small dummy dataset\n",
    "print(\"Creating dummy dataset...\")\n",
    "dataset = create_dummy_dataset(num_samples=16, img_size=256, num_classes=3)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Training config\n",
    "config = {\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'num_epochs': 2,\n",
    "    'num_points': 1024,\n",
    "    'boundary_ratio': 0.5,\n",
    "    'checkpoint_dir': './checkpoints_demo'\n",
    "}\n",
    "\n",
    "# Use lite model for faster training\n",
    "model = EGMNetLite(in_channels=1, num_classes=3, img_size=256)\n",
    "print(f\"Model: {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for a few epochs\n",
    "print(\"\\nStarting training demo...\")\n",
    "trainer = EGMNetTrainer(model, config, device=device)\n",
    "trainer.train(train_loader, num_epochs=2)\n",
    "\n",
    "print(\"\\n‚úÖ Training demo completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c9e44f",
   "metadata": {},
   "source": [
    "## 10. Inference Speed Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_model(model, input_tensor, num_runs=50, warmup=10):\n",
    "    \"\"\"Benchmark inference speed.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(input_tensor)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            start = time.time()\n",
    "            _ = model(input_tensor)\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            times.append(time.time() - start)\n",
    "    \n",
    "    return np.mean(times) * 1000, np.std(times) * 1000  # ms\n",
    "\n",
    "# Benchmark\n",
    "print(\"Benchmarking inference speed...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "\n",
    "for name, model in [('EGM-Net Full', egm_net), ('EGM-Net Lite', egm_lite)]:\n",
    "    mean_time, std_time = benchmark_model(model, test_input)\n",
    "    fps = 1000 / mean_time\n",
    "    print(f\"{name:20s}: {mean_time:.2f} ¬± {std_time:.2f} ms ({fps:.1f} FPS)\")\n",
    "\n",
    "print(\"\\n‚úÖ Benchmark completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a31bd",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb75fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                    EGM-NET ARCHITECTURE SUMMARY                       ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ïë  üî¨ KEY INNOVATIONS:                                                  ‚ïë\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ïë  1. MONOGENIC ENERGY GATING                                          ‚ïë\n",
    "‚ïë     ‚Ä¢ Physics-based edge detection (Riesz Transform)                 ‚ïë\n",
    "‚ïë     ‚Ä¢ Automatically focuses on boundary regions                      ‚ïë\n",
    "‚ïë     ‚Ä¢ Suppresses artifacts in flat regions                           ‚ïë\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ïë  2. GABOR BASIS (vs Fourier)                                         ‚ïë\n",
    "‚ïë     ‚Ä¢ Localized oscillations (Gaussian √ó sin)                        ‚ïë\n",
    "‚ïë     ‚Ä¢ NO Gibbs ringing artifacts                                     ‚ïë\n",
    "‚ïë     ‚Ä¢ Sharp edges remain clean                                       ‚ïë\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ïë  3. DUAL-PATH ARCHITECTURE                                           ‚ïë\n",
    "‚ïë     ‚Ä¢ Coarse Branch: Smooth body regions (Conv decoder)              ‚ïë\n",
    "‚ïë     ‚Ä¢ Fine Branch: Sharp boundaries (Gabor Implicit)                 ‚ïë\n",
    "‚ïë     ‚Ä¢ Energy-gated fusion: Best of both worlds                       ‚ïë\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ïë  4. RESOLUTION-FREE INFERENCE                                        ‚ïë\n",
    "‚ïë     ‚Ä¢ Query at ANY coordinate ‚Üí Infinite zoom                        ‚ïë\n",
    "‚ïë     ‚Ä¢ No retraining needed for different resolutions                 ‚ïë\n",
    "‚ïë     ‚Ä¢ Perfect for high-resolution medical imaging                    ‚ïë\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ïë  5. MAMBA ENCODER                                                    ‚ïë\n",
    "‚ïë     ‚Ä¢ O(N) complexity (vs O(N¬≤) for Transformers)                    ‚ïë\n",
    "‚ïë     ‚Ä¢ Global context awareness                                       ‚ïë\n",
    "‚ïë     ‚Ä¢ Efficient for large images                                     ‚ïë\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ïë  üìä MODEL SIZES:                                                      ‚ïë\n",
    "‚ïë     ‚Ä¢ EGM-Net Full:  ~9.13M parameters                               ‚ïë\n",
    "‚ïë     ‚Ä¢ EGM-Net Lite:  ~635K parameters                                ‚ïë\n",
    "‚ïë     ‚Ä¢ SpectralVMUNet: ~10.31M parameters                             ‚ïë\n",
    "‚ïë                                                                       ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36957ab8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Next Steps\n",
    "\n",
    "1. **Train on real data**: Replace dummy dataset with medical imaging dataset (e.g., Synapse, ACDC)\n",
    "2. **Tune hyperparameters**: Adjust `num_frequencies`, `boundary_ratio`, learning rate\n",
    "3. **Evaluate metrics**: Dice score, IoU, Hausdorff distance\n",
    "4. **Ablation study**: Compare Gabor vs Fourier, with/without energy gating\n",
    "\n",
    "---\n",
    "\n",
    "**Repository**: https://github.com/QuocKhanhLuong/FourierNetwork"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
