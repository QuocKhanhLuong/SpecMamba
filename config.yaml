# =============================================================================
# EGM-Net / SpecMamba - Master Configuration File
# =============================================================================
# This is the SINGLE SOURCE OF TRUTH for all training options.
# All CLI args in train_acdc.py can be overridden via this config.
# =============================================================================

# Quick preset - override individual settings below if needed
# Options: baseline, lite, sota, bio, spectral, attention
preset: "sota"

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
model:
  name: "EGMNet"
  in_channels: 3              # 1=grayscale, 3=RGB
  num_classes: 4              # ACDC: 0=BG, 1=RV, 2=MYO, 3=LV
  img_size: 224               # Input image size
  
  # HRNet Backbone
  backbone:
    type: "hrnet"             # "hrnet" or "simple"
    base_channels: 64         # Channel width (32, 48, 64)
    num_stages: 4             # Number of HRNet stages
    blocks_per_stage: 2       # Blocks per stage
    
  # ==========================================================================
  # BLOCK TYPE - Replaces basic blocks inside HRNet stages
  # ==========================================================================
  block:
    # Available types:
    #   - "basic"             : Standard residual block
    #   - "convnext"          : ConvNeXt Block (SOTA CNN)
    #   - "dcn"               : Deformable Conv v2 ★ RECOMMENDED
    #   - "inverted_residual" : MobileNetV2 style (lightweight)
    #   - "swin"              : Swin Transformer (attention)
    #   - "fno"               : Fourier Neural Operator (spectral)
    #   - "wavelet"           : Wavelet Transform Block
    #   - "rwkv"              : RWKV Block (linear attention)
    type: "dcn"
    depth: 2                  # Default blocks per stage
    
    # Asymmetric block depths (2-4-6 pyramid)
    asymmetric:
      enabled: true
      stage2: 2
      stage3: 4
      stage4: 6
    
    # Dilation Pyramid for DCN (ASPP-style multi-scale)
    dilation_pyramid:
      enabled: true           # Auto: [1, 2, 4, 8, 16, 32]
    
    # Block-specific settings
    convnext:
      drop_path: 0.1
      layer_scale_init: 1e-6
      
    swin:
      num_heads: 8
      window_size: 7
      mlp_ratio: 4.0
      
    fno:
      modes: 16
      mlp_ratio: 2.0
      
    mamba:
      d_state: 16
      d_conv: 4
      expand: 2
      
  # Additional Components
  components:
    use_mamba: false          # Mamba SSM blocks (requires mamba-ssm)
    use_spectral: false       # Spectral FFT processing
    use_pointrend: true       # PointRend for boundary refinement
    use_dog: true             # DoG preprocessing

# =============================================================================
# PREPROCESSING
# =============================================================================
preprocessing:
  # Difference of Gaussians (DoG) - Edge enhancement
  dog:
    enabled: true
    scales: [[1.0, 2.0], [2.0, 4.0]]
    kernel_size: 15
    concat_original: true

# =============================================================================
# SEGMENTATION HEADS
# =============================================================================
heads:
  # Coarse Head (main segmentation output)
  coarse:
    type: "constellation"     # "constellation" (RBF), "linear", "conv"
    enabled: true
    embedding_dim: 2
    init_gamma: 1.0
    
  # Fine Head (implicit refinement)
  fine:
    type: "shearlet"          # "gabor", "shearlet", "none"
    enabled: true
    hidden_dim: 256
    num_layers: 4
    num_frequencies: 64
    use_energy_gating: true
    
  # Shearlet-specific
  shearlet:
    num_orientations: 8
    num_frequencies: 4
    hidden_dim: 256
    
  # Fusion method
  fusion:
    type: "energy_gated"      # "energy_gated", "average", "learned"
    temperature: 1.0

# =============================================================================
# TRAINING CONFIGURATION
# =============================================================================
training:
  # Basic
  epochs: 150
  batch_size: 8
  num_workers: 0
  
  # Optimizer
  optimizer: "adamw"          # "adamw", "sgd", "adam"
  learning_rate: 1e-4
  weight_decay: 1e-5
  
  # Scheduler
  scheduler: "cosine"         # "cosine", "reduce_plateau", "step"
  scheduler_params:
    T_max: 150                # For cosine
    eta_min: 1e-6
    
  # Training Techniques
  grad_clip: 1.0
  use_amp: false              # Mixed precision (AMP)
  early_stop: 30              # Epochs without improvement
  
  # SOTA Strategies
  sota:
    # Boundary Loss
    boundary_loss: true
    boundary_weight: 0.5
    warmup_epochs: 10         # Warmup before adding boundary loss
    
    # Deep Supervision
    deep_supervision: false
    ds_weights: [1.0, 0.5, 0.25, 0.125]
    
  # Point Sampling (for fine head)
  point_sampling:
    enabled: false
    num_samples: 4096
    boundary_ratio: 0.5
    jitter_scale: 0.01
    strategy: "uncertainty_energy"
    
  # Augmentation
  augmentation:
    random_flip: true
    random_rotation: true
    rotation_range: 15

# =============================================================================
# LOSS CONFIGURATION
# =============================================================================
loss:
  # Loss weights
  ce_weight: 1.0
  dice_weight: 1.0
  focal_weight: 0.0           # Set > 0 to enable focal loss
  focal_gamma: 2.0
  boundary_weight: 0.5
  consistency_weight: 0.1     # Multi-scale consistency
  energy_weight: 0.5          # Energy gating loss

# =============================================================================
# EVALUATION CONFIGURATION
# =============================================================================
evaluation:
  # Evaluation mode
  mode: "3d"                  # "2d" (slice-wise) or "3d" (volumetric)
  
  # Test Time Augmentation (TTA)
  tta:
    enabled_val: false        # TTA for validation
    enabled_test: true        # TTA for test
    modes: 8                  # 4 or 8 augmentations
    # 4x: flip + 3 rotations
    # 8x: 4 rotations x (original + hflip)

# =============================================================================
# DATA CONFIGURATION
# =============================================================================
data:
  # Dataset
  dataset: "ACDC"             # "ACDC", "Synapse", "BRATS", etc.
  root: "preprocessed_data/ACDC"
  train_dir: "training"
  test_dir: "testing"
  
  # Split
  train_split: 0.8            # Train/Val split ratio
  seed: 42                    # Random seed for reproducibility
  
  # Data loading
  use_memmap: true            # Memory-mapped loading
  max_cache: 10               # Max volumes in cache
  pin_memory: true

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
output:
  save_dir: "weights"
  exp_name: null              # Auto-generate if null
  save_interval: 50           # Checkpoint every N epochs
  save_last: true
  save_best: true
  save_history: true          # Save training history

# =============================================================================
# LOGGING
# =============================================================================
logging:
  level: "INFO"               # DEBUG, INFO, WARNING, ERROR
  log_interval: 100           # Log every N batches
  val_interval: 1             # Validate every N epochs
  print_model_summary: true
  tensorboard: false

# =============================================================================
# PRESETS REFERENCE
# =============================================================================
# baseline:
#   block.type: "basic"
#   preprocessing.dog.enabled: false
#   heads.fine.enabled: false
#   components.use_pointrend: false
#   evaluation.mode: "2d"
#   ~5M params, fast training
#
# lite:
#   block.type: "inverted_residual"
#   preprocessing.dog.enabled: false
#   heads.fine.enabled: false
#   ~3M params, mobile-friendly
#
# sota: ★ RECOMMENDED
#   block.type: "dcn"
#   block.asymmetric.enabled: true (2-4-6)
#   block.dilation_pyramid.enabled: true
#   components.use_pointrend: true
#   training.sota.boundary_loss: true
#   evaluation.mode: "3d"
#   ~25M params, best accuracy
#
# bio:
#   block.type: "dcn"
#   preprocessing.dog.enabled: true
#   heads.fine.type: "shearlet"
#   Biologically-inspired processing
#
# spectral:
#   block.type: "fno"
#   components.use_spectral: true
#   Fourier-based processing
#
# attention:
#   block.type: "swin"
#   heads.fine.type: "gabor"
#   Transformer-based attention
# =============================================================================
